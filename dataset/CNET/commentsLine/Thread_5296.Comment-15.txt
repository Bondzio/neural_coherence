assuming that you're talking about a desktop pc (notebooks are another matter entirely), you can absolutely upgrade to a better video card later on.
integrated graphics systems, with few exceptions, offer the bare minimum user experience.
they're okay for most typical household tasks and internet browsing, and even for most business / office uses, but for an enjoyable multimedia or gaming experience, you're probably going to want to upgrade to a faster card.
fortunately, all desktop systems include several expansion slots that can accommodate additional cards, including one or two designed specifically for graphics cards.
in new machines, this will be a pci-express slot.
don't get suckered into buying an outdated machine with an agp slot instead!
agp is an older technology on its way out, and graphics cards that fit that standard are older, slower and harder to come by.
if and when you do install a new graphics card, you can disable the integrated graphics in the computer's bios.
even if bios-tweaking is beyond you, most computer systems will automatically detect the new card and direct resources to it instead.
(by the way, 256mb isn't all that much memory when you're talking about today's games, much less tomorrow's!
plus, that's 256mb of shared memory, which means the graphics system doesn't have any memory of its own; it's borrowing from the system ram to store all of its texture information.
this is a very slow way of doing things, even with fast system ram!)
