your so far gone into marketing 3dfx lost market share because they used the AGP Buffer that you speak of being used by graphics cards for performance, you know how slow that makes your graphics?
even with the BEST CPU on the market?
just consider, a 6800GT has around 35.2GB/s of onboard bandwidth, meaning the RAM/GPU have 35.2GB/s between each other, that is FAST AGP 8x has about 2.11GB/s interfacing to RAM with between 2.1GB/s and around 10GB/s (top end dual channel DDR2 could probably break that) it would slow the video rendering down by 30x-40x if a 6800GT started to fill the AGP Buffer, it's too slow PCIE works almost the same way, it's just FASTER in addition to that, what I say does reign true, and if you goto any serious performance based forum (C|Net is more like IT and newbies) your going to get laughed off the face of the internet for making the claims your making Intel is, and has been, slower I can back this up even by comparing the K7 to the P4, in MHZ for MHZ, hell Pentium III would kick the P4's teeth in MHZ for MHZ (Pentium M is a heavily modified Pentium 3 (it's P3 based) and it kicks the P4, and in some cases even the K8's, teeth in, at a &quot;low&quot; 2.1GHZ) clock speed means nothing it's just the operational speed of the chip, it all comes down to waht it can accomplish in those cycles Intel's Itanium2 server chip is clocked a 1.6GHZ, and excusing it's IA-64 nativity (vs K7/K8 and P4's x86-32 or x86-64 natvity, Windows requries x86-32 or x86-64, so do most versions of Linux) the Itanium2 could mop the floor with any CPU in the world, in a mhz for mhz competition Itanium2 is capable of a maximum of 21 IPC!
7 FPU operations per clock 7 ALU and 7 other (I honestly do not remember the third slice of the pie) it does more FPU operations per clock than the P4 does total operations and 2 less tahn K8 P4 does 2 FPU operations per clock, and K8 does 3 Itanium2 is designed and built for nothing but number crunching (why do you think Colombia uses a few thousand of them, and why do you think it's the #2 computer in the world) Itanium2 is a monster in all respects, it's just the lack of software, low yields (the dies are huge, have large L2 caches (2-8MB) and are complex to produce) and high cost (due to low yields and high cache) essentially it's too expensive for practical use in a consumer world at $1600-$2200 per CPU and a software support of only a few OS' (that's low, that's very low, x86-32/x86-64 supports hundreds if not thousands of OS') which all cost a lot/are special distro's avliable to enterprise clients only it's just like Silicon Graphics' R series CPU's from the early 1990's (such as those found in the Indigo2 workstation which is simmilar to the machines used to animate the movie Toy Story (the up model Inidgo2 is what was used)) those require a MIPS ISA OS, such as IRIX which is also hard to find/does not support much and if you'd really like to get into the ATi/nVidia battle ATi does lack features, which make it the #2 part in terms of future use, and performance ATi lacks Shader Model 3.0 (which is the requirement that keeps ATi from having a DirectX 9.0c Certified Part (currently only nVidia has a DX 9.0c Cert.
part)) the lack of SM3.0, and the fact that Radeon X still uses FP24, and not the new FP32 (FP between 24 and 32 isn't such a big deal, and won't be for another year-ish, which is probably why ATi didn't go FP32 (nVidia is notorious for advancing things beyond what the time requires, SM3.0 however is something that is required now) ATi's Radeon 9 series of cards have issues with FarCry, and in some cases flat out won't play the game Radeon 9 is already known to be un-supportive of the Half-Life 2 expansion, due to it's amazingly inferior technology (GeForce FX isn't much better honestly) Radeon X is going to support the Half-Life 2 expansion, yet it's not going to support it at 100% GeForce 6's only issue is going to be does it have the power, and current estimates say YES GeForce 7 will have no issues, it has more than enough power and all the features of GeForce 6 + some more do not sit there and say ATi and nVidia are equals ATi usually nets higher benchmark scores, and usually nets better acceptance in the performance crowd due to various RMA Policies adapted by them and a few of their OEM's (no question asked RMA's are very nice when you've just fried a $550 card OC'ing it, and you can get a new one for free sans postage) nVidia always has had higher tech features, and supported newer games with older hardware...it's how they put 3dfx out of business for god's sake consider, 3dfx supported nothing higher than 16-bit color until VSA-100, nVidia had had 32-bit for 2-3 yrs by that time, had refined it, and had also refined Direct3D support (something which 3dfx also had issues with) nVidia runs ahead of the pack in terms of technolgy, and currently in terms of performance if you want to waste your money on a Radeon 9 or Radeon X that is A) already outdated and B) will require replacement by christmas to play any game; go for it as to the CPU comparison, there is a #1 CPU, but it depends on what your doing if your talking the absolute fastest CPU in the world ignoring software side, it would probably be without a question Itanium2 (or the upcoming Itanium3) if your talking fastest CPU in the world in terms of gaming, no questions asked, it's AMD's Athlon64 FX-57 if your talking fastest CPU in the world in terms of dual-cored, it's AMD with one exception Intel reigns over AMD in 1 thing, and they have for a few years, Video Encoding AMD is not slow, but just compare these http://www.tomshardware.com/cpu/20050603/stresstest-28.html aside the fact from ALL of that I will not reply to you until you can show maturity, and intelligence about what your saying, your sitting there and telling me that AMD is inferior due to clock speed, while THG is sitting there showing time after time after time, AMD WINS you sit there and tell me ATi is better because you say so, so what?
who cares what you think, your view isn't the right view, it's your opinion my opinion is that nVidia is better because I like their drivers and ease of use for multi-monitor display systems compared to ATi the facts however show that nVidia ALSO has features that ATi lacks, ATi is adding these features in their Q3 release of R520, they are adding these why?
if their not needed why add them?
why have the dies re-tapped because they didn't work as spec'ed, if the features aren't needed?
why spend millions of dollars developing the GPU to use simmilar features to your competition?
why?
because ATi is in #2 they are behind nVidia, they aren't compatable with the latest version of DirectX (which ultimatly determines what games will play, and what wont) and as I write this your digging up some rubbish about emulation of SM3.0 I will tell you right now, that is a VERY expensive (I say expensive in terms of performance cost) process and your &quot;oh so good&quot; Radeon X will be a little paperweight given how slow the thing will ooze through SM3.0 emulation as to benchmarking, i've come to talk about it too Everest is not designed to compare systems, and is not a very accurate benchmark, it calculates oddly, and is not commonly accepted nor used by anyone, it's more like a toy...like uGuru, but it's free and doesn't require an Abit motherboard if you were to take a system with a 500MHZ AMD AthlonXP 3200+ (1700MHZ underclocked) with a GeForce 6800GT, and then run it at correct speed I can tell you right now your 3DMark2003 scores will be around 9000-10000 at 500MHZ and around 10500 to 10700 at 2200MHZ the CPU score however, WILL change a bit more drastically 3DMark2005 would do about the same (except 10,000 isn't going to be the score) your also comparing to probably a 3.73GHZ Pentium 4 EE using a 1066 FSB giving it over 6.4GB/s of bandwidth your lucky to get 1.1 your comparing an $1100 CPU (which could be called limited edition due to it's short shelf life) to your $50...thing you cannot, and should not, do that that's like comparing a Dodge Viper to a Geo Metro, assuming both are fully stock and using identical grade fuels, and that both are brand new and un-flawed, and then saying that the Metro should be winning... consider what the Viper has on the Metro...aside from costing around a dozen times as much it has about 450-550 HP and over twice the cylinders it's not fair for the Metro an AMD of comparable power would however run with that Intel such as an FX-53 or FX-55, the FX-57 would eat it alive now, given that your A) unwilling to learn and B) unwilling to get of your horse you can take your &quot;i'm so good at computers and know what i'm doing&quot; and stick it, i'm personally sick of trying to explain this, I understand most people fall prey to Intel's marketing, that was the design behind Pentium 4 to make a chip that clocks so high that people think it's better no matter what, and you've fallen for it (Intel openly admitted this at the launch of Willamette) if Intel were so much better, and so much faster, why do 5/6ths if not all gamers and enthusiasts use AMD?
why do all of the enthusiast benchmarkers, who score close to 16,000 in 3DMark2005 use AMD, if Intel is so much better, why use AMD then?
you need to wake up and smell the lies, Intel designed NetBurst, Willamette, all of it, it's all marketing ploys Intel realizes that Pentium 4 has to run too fast to keep up with AMD, consider, if Pentium 4 and AMD were MHZ for MHZ, why even make a 3.8GHZ P4?
AMD's fastest chip is 2.8GHZ...why not stop at the 3.2?
or the 3.4?
or, why not make a 4.0?
they didn't make a 4.0 because it's too hot and doesn't help their fight against AMD, they are SLOWER a 3.2E is slower than a 3200+ you can sit there and tell me i'm wrong all you want, and you can reply to this going &quot;ha, I beat you, you get scared or beaten?&quot; all you want it just goes to show that when given information, people prefer blatant ignorance and raw stupidity, versus accepting that they were wrong, being a man (or woman, but i'm assuming your male) about it, and letting someone teach you I wouldn't walk into a mechanic's shop and say &quot;well, i'm going to build a car, I know roughly what it needs, and you can't tell me other wise, but i'd like help&quot; I don't even know enough about cars or car building to know what components i'd even need to start, let alone what would work/not work your claiming to know more than all of us here, so if we are so inferior, why don't you go build your little system, and by the time that A) the PSU you get for free with the case is junk and it burns everything out B) you rebuild and C) you come back trying to talk big we can explain again why it didn't work, around that time your 2nd junk PSU should give out, and you'll start accepting our advice or you'll just man (or woman) up to it, and realize that you aren't the man (or woman) and that someone MIGHT know what their talking about, the reason i'm done helping you is that i'm sick and tired of dealing with your immaturity and inability to accept advice being given to you by someone who has done this many times and who knows a rather fair deal about what i'm doing i'm not trying to steer you in the wrong direction, all of my advice is geared towards getting you the most power, for the least cash... if you'd like to say that ATi vs nVidia is all the same and it's just personal pref, i'd agree with you if it were 2003 or 2004 but it's not, it's 2005 and SM3.0 is a reality now, if we were back in 2003 i'd even be saying go go ATi, given that, while not a viable solution now, Radeon 9 was better than GeForce FX (in general design) but the tables turned, just like AMD and Intel AMD brought Athlon64 out, and Intel hasn't been on the performance throne since even with dual core, Intel's only advantage is video encoding...I mean, your going to spend $300-$1100 on a CPU from Intel which will perform lesser than the AMD equivalent (i'll warn you, AMD's dual cores are coming in expensive) just to disagree with me?
your seriously that inable to accept advise that your going to throw your money away on retail boxed HD's over buying the SATA cables seperate and saving $10-$100, your going to buy a Radeon X and have to upgrade by X-mas and end up spending around $1k on gfx when you could do it for $400, and your going to spend all that on a CPU, and get less performance in everything except 1 thing, that you won't be doing 24/7 (unless your main goal is that, and you have not stated that as your main goal) and your going to do all this at an estimated waste of $1200 by December 2005, JUST TO SHOW ME UP AND GO AGAINST ME?!
THATS INSANE I could care less what you think of me, I could care less if you walk away from this going &quot;man that Ozos guy is some idiot, I wish he'd just die&quot; but I do care if you waste money, more from the sense that A) I don't want to deal with your crying about needing to upgrade in 3 months and B) seeing people waste money after falling for marketing ploys (even people that drive me up the walls, like you) just burns me but if your really that hell bent on not accepting my advice, you have got to be the most hard headed person i've ever met... in addition, 1940MB is not a percantage i'm guessing you mean 1940MB/s which is VERY low in terms of RAM bandwidth and juding the system's power and speed by it's boot speed, a few things will affect boot speed mainly: A) PSU, time to power good signal, the faster this is, the faster the system can start the boot process (average is around 500ms) B) BIOS settings, depending on what you have it do and not do during boot, depends on how fast it can POST C) OS choice, depending on what OS your using, depends on how fast it loads, some will do better than others D) finally we get to CPU clock speed, and it doesn't really make a difference as long as you've met the WindowsXP min.
req.
which is around 300MHZ I could have a 667MHZ Pentium 3 (chose that to ensure i'm far enough over min.
req.)
and a 3200MHZ Pentium 4 side by side using WindowsXP with quick BIOS optimizations and some tweaking to WindowsXP's boot.ini file I could have the Pentium 3 machine up as fast if not faster than Pentium 4 some things to improve your own boot speed: get rid of spyware edit boot.ini i'd also like to note, my 1MHZ Apple can boot faster than my 2.2GHZ AMD or 2.1GHZ Intel (which according to you should be better, my Intel would have to run at over 3GHZ (given that it's Willamette, the worst Pentium 4 core) to compare to my AMD) and my Apple is running 1/2200nd the speed of the AMD it boots in under 2 seconds, and is ready to go for whatever task I need boot speed has nothing to do with raw power let's consider a computer like Mare Nostrum or Blue Gene/L (i'm not talking the beta) Blue Gene/L could take between 10 minutes and probably upwards of an hour to boot and I gurantee you, your computer couldn't even hold a fraction of a candle to Blue Gene/L nobody's could and using a CPU intensive benchmark (as Blue Gene/L is for the most part 3D innept) you could probably show Blue Gene/L as faster I mean, if you want a really prescise benchmark, try SuperPI... but, as far as every thing else goes, I hope you have a good day, and I hope you have a good lunch or dinner depending on your time zone/when you read this Good-Bye, Ozos PS as to the semi-personal attacks, I do not mean to make attacks against you, I mainly mean to have a bit more attitude behind my words than a generic &quot;Ben Stein&quot; reply
