1.1.1	AnandTech benchmarks seem to show that the 260 runs about 30W less at idle and that the two are essentially equal under load .	St
1.1.2	Given that the card will spend a vast majority of time at or near idle , does it make sense to spend nearly double the price , once the 9800 price cuts hit ( making the GTX+ roughly $ 230 ) ?	Ques
1.2.1	At current California prices for electricity the financial cost for the electrical power difference between the cards would be $ 37.74 ( based on $ .1436 per kWh ) per year , if you run your PC 24/7 .	St
1.2.2	I 'm clueless how many tonnes of CO2 that is .	St
1.2.3	Obviously it 'd be cooler to run .	St
1.2.4	And sexier cuz it 's new .	St
1.2.5	XD	St
1.3.1	But lets take a real bill and find a number to use .	St
1.3.2	Using the total bill divided by the number of KWh I arrive at 15.68 cents per KWh .	St
1.3.3	1 year = 8,760 hours 30 Watts for 1 year = 262.8 KWh or 41.21 bucks .	St
1.3.4	You decide here .	St
1.3.5	But your usual gamer desktops idles at 200 Watts so let 's do that .	St
1.3.6	About 275 a year .	St
1.3.7	Bob	St
1.4.1	you buy a high performance video card based on it 's gaming performance , not it 's power draw .	St
1.4.2	if you only game at 1680x1050 , a 9800gtx will play most every game just as smoothly as a gtx 260. also consider the new hd 4870 which gives comparable performance to a gtx 260 for $ 100 less .	St
